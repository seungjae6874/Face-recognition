{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese-Networks.ipynb",
      "provenance": [],
      "mount_file_id": "198aOXflptNbfc12by2fPGTqRcEKEMO3y",
      "authorship_tag": "ABX9TyMOx2GkCyZOy6aTRz/XkEqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungjae6874/Face-recognition/blob/master/siamese_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t77qSgwpTy9o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjYR9CuZT1Hu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "Imports\n",
        "모든 import 해야 할 것들을 정의해 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_O6nyG_Lsah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-meiVOuoT-2G",
        "colab_type": "text"
      },
      "source": [
        "Helper functions\n",
        "필요한 함수들을 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4B6nGlkRtdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img,text = None, should_save = False):\n",
        "  npimg = img.numpy()\n",
        "  plt.axis(\"off\")\n",
        "  if text:\n",
        "    plt.text(75,8,text, style='italic',fontweight='bold',\n",
        "             bbox={'facecolor':'white','alpha':0.8,'pad':10})\n",
        "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "    plt.show()\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3lmDtDBUE_0",
        "colab_type": "text"
      },
      "source": [
        "Configuration Class\n",
        "간단한 클래스들을 통해 data사진이 있는 경로를 선언해주고 에폭과 배치사이즈를 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTm_6ChOTZy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "  training_dir = \"/content/drive/My Drive/siamese/data/faces/training\"\n",
        "  testing_dir = \"/content/drive/My Drive/siamese/data/faces/testing\"\n",
        "  train_batch_size = 64\n",
        "  train_number_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3dPgEm9UPr4",
        "colab_type": "text"
      },
      "source": [
        "Custom Dataset Class\n",
        "데이터셋은 한 쌍의 이미지들로써 생성됩니다.\n",
        "0의 값은 정답의 이미지를 갖는 쌍\n",
        "1의 값은 거짓의 사진 즉, 일치하지 않는 사진인 쌍을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep85M89_SNIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "        self.should_invert = should_invert\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        #we need to make sure approx 50% of images are in the same class\n",
        "        should_get_same_class = random.randint(0,1) \n",
        "        if should_get_same_class:\n",
        "            while True:\n",
        "                #keep looping till the same class image is found\n",
        "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
        "                if img0_tuple[1]==img1_tuple[1]:\n",
        "                    break\n",
        "        else:\n",
        "            while True:\n",
        "                #keep looping till a different class image is found\n",
        "                \n",
        "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
        "                if img0_tuple[1] !=img1_tuple[1]:\n",
        "                    break\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        \n",
        "        if self.should_invert:\n",
        "            img0 = PIL.ImageOps.invert(img0)\n",
        "            img1 = PIL.ImageOps.invert(img1)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIz9p9R6Urka",
        "colab_type": "text"
      },
      "source": [
        "Using Image Folder Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1i11ahzTSaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_dataset= dset.ImageFolder(root = Config.training_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjxbCKykU1fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
        "                                                                       transforms.ToTensor()]),should_invert=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFoGVkQXWttE",
        "colab_type": "text"
      },
      "source": [
        "Visualising some of the data\n",
        "이제 데이터를 로드한 후에 훈련시에는 shuffle을 하고 한번 돌려보자\n",
        "한쌍의 사진에 대해 1이면 두 사진은 맞지 않고 0이면 같은 인물임을 판단해낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfBTaZtBVS8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "e29fadf3-8526-4f12-b5d4-d955711405b6"
      },
      "source": [
        "vis_dataloader = DataLoader(siamese_dataset,shuffle=True,num_workers=8,batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "example_batch = next(dataiter)\n",
        "concatenate = torch.cat((example_batch[0],example_batch[1]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenate))\n",
        "plt.show()\n",
        "print(example_batch[2].numpy())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKg\ncV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZ\nLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDI\ndAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFC\npgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQ\nMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2A\nkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkC\nhEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwX\nIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6\nACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHT\nBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZ\nLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDI\ndAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFC\npgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQ\nMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnkSIGyXa4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}