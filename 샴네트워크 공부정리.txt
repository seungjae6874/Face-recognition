샴 네트워크 의 기본
- 삼중항 손실함수 : anchor (기준 이미지), positive(긍정의 정답이미지), negative(부정의 이미지 오답)
학습내용
삼중항 손실 함수는 항상 하나의 이미지를 기준으로, 같은 사람인 것을 뜻하는 “긍정 이미지”와 다른 사람인 “부정 이미지” 의 거리를 구합니다. 즉, 한번에 3개의 이미지를 보게 됩니다. 
기준이 되는 이미지를  A , 긍정 이미지를  P, 부정 이미지를 N  으로 두겠습니다.
우리의 목적은  A 와 P 사이의 거리가 항상 A  와 N  사이의 거리보다 작거나 같게 만들어야합니다. d(x, y) = || f(x) - f(y) ||^2 ,  결국 ∣∣f(A)−f(P)∣∣^​2  ​​≤ ∣∣f(A)−f(N)∣∣^2
​​ 
이는 아래와 같이 변형 됩니다.
∣∣f(A)−f(P)∣∣^​2 ​​− ∣∣f(A)−f(N)∣∣^2 ≤0 
위의 식을 만족하는 자명한 방법중 하나는 두 거리가 모두 0이 되는 것입니다. 따라서 신경망이 무조건 0을 반환하지 않게 하기 위해, 신경망으로 하여금 모든 인코딩이 같지 않다는 것을 알려줘야합니다.
따라서 목적함수를 약간 수정합니다.
∣∣f(A)−f(P)∣∣^​2 ​​− ∣∣f(A)−f(N)∣∣^2  +α≤0 
 
α  는 하이퍼파라미터입니다. 마진이라고 불리기도 합니다. 마진의 역할은 두 거리의 값이 차이가 충분한 거리를 갖게 만드는 것입니다.
단일 손실함수는 아래와 같습니다.
 
L(A, P, N) = max( ∣∣f(A)−f(P)∣∣^​2 ​​− ∣∣f(A)−f(N)∣∣^2 +α, 0)
여기서 max 함수의 역할은 거리의 차이값이 얼만큼 음수인지는 신경쓰지 않게하기 위함입니다. 
전체 손실 함수는 아래와 같습니다.
 
J = \displaystyle \sum_{i=1}^m L(A^{(i)}, P^{(i)}, N^{(i)})
J=
​i=1
​∑
​m
​​L(A
​(i)
​​,P
​(i)
​​,N
​(i)
​​) 
훈련 세트인  
A, P, N 
A,P,N 를 무작위로 고르면 제약식을 를 쉽게 달성하게 됩니다. 왜냐면 무작위로 뽑힌 두장의 사진에서 확률적으로  
A, N 
A,N 이  
A, P
A,P  보다 훨씬 다를 것이기 때문입니다. 즉,  
d(A, N)
d(A,N)  이  
d(A, P)+\alpha
d(A,P)+α  보다 클 확률이 높다는 말입니다.
따라서 훈련세트를 만들 때 학습하기 어렵게 만들어야합니다.
 
d(A, P)
d(A,P) 가  
d(A, N)
d(A,N)  비슷하면 어렵게 만드는 효과를 얻을 수 있습니다.
대부분의 경우에 제약식을 만족 하지 않게 훈련 세트를 만드는 것은 경사 하강법이 더 효율적으로 일을 하게 만듭니다.